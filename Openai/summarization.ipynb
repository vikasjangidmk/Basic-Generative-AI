{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Correcting the argument name\n",
    "model = OpenAI(openai_api_key=api_key, temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "make it that easy so that a 5 year old would understand\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"text\"],\n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarisation_text = \"\"\"\n",
    "\n",
    "The President of Sweden commended the efforts of Landstorm Arlanda, a vital organization contributing to the country's safety and preparedness. Situated near Arlanda Airport, the group focuses on emergency response, disaster management, and civil defense training. Known for its discipline and dedication, Landstorm Arlanda often collaborates with local authorities and international teams, ensuring Sweden remains resilient during crises. The President highlighted their role in safeguarding communities and fostering a spirit of unity, calling them \"a cornerstone of our national defense system.\"  \n",
    "\n",
    "Their recent initiatives include advanced training programs for volunteers and innovative disaster simulations. With such efforts, they inspire citizens to take active roles in ensuring the safety and sustainability of Sweden.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%INSTRUCTIONS:\\nPlease summarize the following piece of text.\\nmake it that easy so that a 5 year old would understand\\n\\n%TEXT:\\n\\n\\nThe President of Sweden commended the efforts of Landstorm Arlanda, a vital organization contributing to the country\\'s safety and preparedness. Situated near Arlanda Airport, the group focuses on emergency response, disaster management, and civil defense training. Known for its discipline and dedication, Landstorm Arlanda often collaborates with local authorities and international teams, ensuring Sweden remains resilient during crises. The President highlighted their role in safeguarding communities and fostering a spirit of unity, calling them \"a cornerstone of our national defense system.\"  \\n\\nTheir recent initiatives include advanced training programs for volunteers and innovative disaster simulations. With such efforts, they inspire citizens to take active roles in ensuring the safety and sustainability of Sweden.\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompt.format(text = summarisation_text)\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "make it that easy so that a 5 year old would understand\n",
      "\n",
      "%TEXT:\n",
      "\n",
      "\n",
      "The President of Sweden commended the efforts of Landstorm Arlanda, a vital organization contributing to the country's safety and preparedness. Situated near Arlanda Airport, the group focuses on emergency response, disaster management, and civil defense training. Known for its discipline and dedication, Landstorm Arlanda often collaborates with local authorities and international teams, ensuring Sweden remains resilient during crises. The President highlighted their role in safeguarding communities and fostering a spirit of unity, calling them \"a cornerstone of our national defense system.\"  \n",
      "\n",
      "Their recent initiatives include advanced training programs for volunteers and innovative disaster simulations. With such efforts, they inspire citizens to take active roles in ensuring the safety and sustainability of Sweden.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe President of Sweden praised a group called Landstorm Arlanda for helping keep the country safe. They are located near an airport and focus on preparing for emergencies and training people for disaster management. Landstorm Arlanda works with others to make sure Sweden is strong during difficult times. The President called them an important part of the country's defense. The group has been doing projects like teaching volunteers and doing practice disasters to encourage people to help protect Sweden.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample1.txt\",\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bhagat Singh (born September 27, 1907, Lyallpur, western Punjab, India [now in Pakistan]—died March 23, 1931, Lahore [now in Pakistan]) was a revolutionary hero of the Indian independence movement.\\n\\nBhagat Singh attended Dayanand Anglo Vedic High School, which was operated by Arya Samaj (a reform sect of modern Hinduism), and then National College, both located in Lahore. He began to protest British rule in India while still a youth and soon fought for national independence. He also worked as a writer and editor in Amritsar for Punjabi- and Urdu-language newspapers espousing Marxist theories. He is credited with popularizing the catchphrase “Inquilab zindabad” (“Long live the revolution”).\\n\\nIn 1928 Bhagat Singh plotted with others to kill the police chief responsible for the death of Indian writer and politician Lala Lajpat Rai, one of the founders of National College, during a silent march opposing the Simon Commission. Instead, in a case of mistaken identity, junior officer J.P. Saunders was killed, and Bhagat Singh had to flee Lahore to escape the death penalty. In 1929 he and an associate lobbed a bomb at the Central Legislative Assembly in Delhi to protest the implementation of the Defence of India Act and then surrendered. He was hanged at the age of 23 for the murder of Saunders.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_token = model.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\",\"\\n\"],chunk_size = 500,chunk_overlap=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Bhagat Singh (born September 27, 1907, Lyallpur, western Punjab, India [now in Pakistan]—died March 23, 1931, Lahore [now in Pakistan]) was a revolutionary hero of the Indian independence movement.'),\n",
       " Document(metadata={}, page_content='\\nBhagat Singh attended Dayanand Anglo Vedic High School, which was operated by Arya Samaj (a reform sect of modern Hinduism), and then National College, both located in Lahore. He began to protest British rule in India while still a youth and soon fought for national independence. He also worked as a writer and editor in Amritsar for Punjabi- and Urdu-language newspapers espousing Marxist theories. He is credited with popularizing the catchphrase “Inquilab zindabad” (“Long live the revolution”).'),\n",
       " Document(metadata={}, page_content='\\nIn 1928 Bhagat Singh plotted with others to kill the police chief responsible for the death of Indian writer and politician Lala Lajpat Rai, one of the founders of National College, during a silent march opposing the Simon Commission. Instead, in a case of mistaken identity, junior officer J.P. Saunders was killed, and Bhagat Singh had to flee Lahore to escape the death penalty. In 1929 he and an associate lobbed a bomb at the Central Legislative Assembly in Delhi to protest the implementation of the Defence of India Act and then surrendered. He was hanged at the age of 23 for the murder of Saunders.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([text])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm=model,chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapReduceDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=OpenAI(client=<class 'openai.api_resources.completion.Completion'>, temperature=0.9, model_kwargs={}, openai_api_key='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', openai_proxy='', logit_bias={}), output_parser=StrOutputParser(), llm_kwargs={}), reduce_documents_chain=ReduceDocumentsChain(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=OpenAI(client=<class 'openai.api_resources.completion.Completion'>, temperature=0.9, model_kwargs={}, openai_api_key='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', openai_proxy='', logit_bias={}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='text')), document_variable_name='text')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_12564\\3615216792.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = chain.run(docs)\n"
     ]
    }
   ],
   "source": [
    "output = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bhagat Singh, a revolutionary hero, was born in 1907 in Punjab, India and died in 1931 in Lahore, Pakistan. He was a leader in the Indian independence movement and popularized the phrase \"Inquilab zindabad.\" He protested British rule and advocated for Marxist theories through his writing and editing. He plotted to kill a police chief, but accidentally killed a junior officer instead. He later bombed the Central Legislative Assembly in Delhi and was executed at the age of 23 for the murder.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize a pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai Pr oject s:\n",
      "1O p e n a i  P r o j e c t s :\n",
      "Her e ʼ s a br e ak do wn of e ach line in y our code:\n",
      "import logging\n",
      "Impor t s t he logging  module  f or handling log messages, useful f or debugging  \n",
      "and tracking e v ent s dur ing pr ogram e x ecution.\n",
      "from aiogram import Bot, Dispatcher, executor, types\n",
      "Impor t s k e y component s fr om t he aiogram  libr ar y , including:\n",
      "Bot  f or int eracting with the T elegram Bot API.\n",
      "Dispatcher  f or managing bot e v ent handlers.\n",
      "executor  f or running the bot.\n",
      "types  f or defining message and e v ent t ypes.\n",
      "from dotenv import load_dotenv\n",
      "Impor t s load_dotenv  fr om dotenv  t o lo ad en vir onment v ar iables fr om a .env  file.\n",
      "import osOpenai Pr oject s:\n",
      "2Impor t s t he os  module  f or int eracting with the operating syst em, p ar ticular l y  \n",
      "t o access en vir onment v ar iables.\n",
      "load_dotenv()\n",
      "Lo ads en vir onment v ar iables fr om a .env  f ile  int o the scr iptʼ s en vir onment.\n",
      "python\n",
      "Copy code\n",
      "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
      "R etr ie v es t he T elegr am bot t ok en  fr om en vir onment v ar iables using \n",
      "os.getenv() .\n",
      "python\n",
      "Copy code\n",
      "logging.basicConfig(level=logging.INFO)\n",
      "Conf igur es t he logging module  t o displa y messages at the INFO le v el or  \n",
      "higher .\n",
      "python\n",
      "Copy code\n",
      "bot = Bot(token=TELEGRAM_BOT_TOKEN)\n",
      "Initializ es t he bot  using the r etr ie v ed T elegram bot t ok en.\n",
      "python\n",
      "Copy codeOpenai Pr oject s:\n",
      "3dp = Dispatcher(bot)\n",
      "Initializ es t he disp at cher  which will manage and r out e the messages and  \n",
      "commands t o the cor r ect handlers.\n",
      "@dp.message_handler(commands=['start', 'help'])\n",
      "async def command_start_handler(message: types.Message):\n",
      "    \"\"\"\n",
      "    This handler receives messages with `/start` or `/help` c\n",
      "ommand\n",
      "    \"\"\"\n",
      "    await message.reply(\"Hi\\nI am Echo Bot!\\nPowered by princ\n",
      "e.\")\n",
      "Def ines a message handler  f or the /start  and /help  commands. When a user  \n",
      "sends one of these commands, the bot r eplies with a gr eeting message.\n",
      "@dp.message_handler()\n",
      "async def echo(message: types.Message):\n",
      "    \"\"\"\n",
      "    This will return echo\n",
      "    \"\"\"\n",
      "    await message.answer(message.text)\n",
      "Def ines a gener al message handler . F or an y other message, the bot will r epl y  \n",
      "b y echoing the same t e x t it r eceiv es.\n",
      "python\n",
      "Copy code\n",
      "if __name__ == \"__main__\":Openai Pr oject s:\n",
      "4    executor.start_polling(dp, skip_updates=True)\n",
      "Runs t he bot  b y polling T elegram f or updat es (messages or commands). The \n",
      "skip_updates=True  ensur es that an y pending updat es ar e ignor ed when the bot  \n",
      "st ar t s.\n",
      "Her e ʼ s a det ailed e xplanation of e ach p ar t of y our code, along with the r e asoning  \n",
      "behind wh y these st eps ar e necessar y:\n",
      "python\n",
      "Copy code\n",
      "class Reference:\n",
      "    '''\n",
      "    A class to store previously received responses from the O\n",
      "penAI API.\n",
      "    '''\n",
      "    def __init__(self) -> None:\n",
      "        self.response = \"\"\n",
      "Def ines a Reference  class  t o st or e the last r esponse generat ed b y the OpenAI  \n",
      "API. The response  at tr ibut e will k eep track of con v ersation hist or y or cont e x t.\n",
      "R e ason:  By st or ing pr e vious r esponses, the bot c an maint ain a  \n",
      "con v ersation b y r ef er encing p ast int eractions, making it f eel mor e  \n",
      "coher ent and continuous.\n",
      "python\n",
      "Copy code\n",
      "reference = Reference()\n",
      "model_name = \"gpt-3.5-turbo\"Openai Pr oject s:\n",
      "5Cr e at es an inst ance of t he Reference  class  t o st or e con v ersation hist or y .\n",
      "Set s t he model name  f or the OpenAI API t o \"gpt-3.5-turbo\" .\n",
      "R e ason:  The reference  object will st or e the con v ersation cont e x t bet w een  \n",
      "the bot and the user , and the model name is needed f or generating  \n",
      "r esponses using OpenAI's GPT model.\n",
      "python\n",
      "Copy code\n",
      "bot = Bot(token=TELEGRAM_BOT_TOKEN)\n",
      "dispatcher = Dispatcher(bot)\n",
      "Initializ es t he bot  using the TELEGRAM_BOT_TOKEN , and a dispatcher  is cr e at ed t o  \n",
      "manage incoming messages.\n",
      "R e ason:  The dispatcher  r out es the messages t o the cor r ect handler ,  \n",
      "making the bot c ap able of int eracting with users thr ough T elegram.\n",
      "python\n",
      "Copy code\n",
      "def clear_past():\n",
      "    \"\"\"A function to clear the previous conversation and cont\n",
      "ext.\"\"\"\n",
      "    reference.response = \"\"\n",
      "Def ines a function t o cle ar p ast r esponses  b y set ting reference.response  t o an  \n",
      "empt y str ing.\n",
      "R e ason:  This allo ws the user t o cle ar the con v ersation hist or y , r eset ting  \n",
      "the cont e x t so the bot st ar t s fr esh. This could be useful if the user want s  \n",
      "t o change t opics or r est ar t the con v ersation.\n",
      "python\n",
      "Copy code\n",
      "@dispatcher.message_handler(commands=['clear'])Openai Pr oject s:\n",
      "6async def clear(message: types.Message):\n",
      "    \"\"\"\n",
      "    A handler to clear the previous conversation and context.\n",
      "    \"\"\"\n",
      "    clear_past()\n",
      "    await message.reply(\"I've cleared the past conversation a\n",
      "nd context.\")\n",
      "Cr e at es a handler f or t he /clear  command , which c alls the clear_past()  \n",
      "function t o cle ar the con v ersation cont e x t.\n",
      "R e ason:  This pr o vides the user with a wa y t o r eset the con v ersation  \n",
      "hist or y thr ough the /clear  command.\n",
      "python\n",
      "Copy code\n",
      "@dispatcher.message_handler(commands=['start'])\n",
      "async def welcome(message: types.Message):\n",
      "    \"\"\"\n",
      "    This handler receives messages with `/start` command.\n",
      "    \"\"\"\n",
      "    await message.reply(\"Hi\\nI am Tele Bot!\\Created by Bappy.  \n",
      "How can I assist you?\")\n",
      "Def ines a handler f or t he /start  command , sending a w elcome message t o  \n",
      "the user when the y initiat e a con v ersation with the bot.\n",
      "R e ason:  The /start  command ser v es as a st andar d entr y point f or most  \n",
      "bot s. I t intr oduces the bot and let s the user kno w itʼ s r e ad y t o int eract.\n",
      "python\n",
      "Copy code\n",
      "@dispatcher.message_handler(commands=['help'])\n",
      "async def helper(message: types.Message):Openai Pr oject s:\n",
      "7    \"\"\"\n",
      "    A handler to display the help menu.\n",
      "    \"\"\"\n",
      "    help_command = \"\"\"\n",
      "    Hi There, I'm Telegram bot created by Bappy! Please follo\n",
      "w these commands -\n",
      "    /start - to start the conversation\n",
      "    /clear - to clear the past conversation and context.\n",
      "    /help - to get this help menu.\n",
      "    I hope this helps. :)\n",
      "    \"\"\"\n",
      "    await message.reply(help_command)\n",
      "Def ines a handler f or t he /help  command , sending a list of a v ailable  \n",
      "commands and their descr iptions t o the user .\n",
      "R e ason:  The help menu giv es users an o v er vie w of what the y c an do with  \n",
      "the bot, impr o ving usabilit y b y sho wing the a v ailable commands.\n",
      "python\n",
      "Copy code\n",
      "@dispatcher.message_handler()\n",
      "async def chatgpt(message: types.Message):\n",
      "    \"\"\"\n",
      "    A handler to process the user's input and generate a resp\n",
      "onse using the ChatGPT API.\n",
      "    \"\"\"\n",
      "    print(f\">>> USER: \\n\\t{message.text}\")\n",
      "    response = openai.ChatCompletion.create(\n",
      "        model = model_name,\n",
      "        messages = [\n",
      "            {\"role\": \"assistant\", \"content\": reference.respon\n",
      "se},  # role assistant\n",
      "            {\"role\": \"user\", \"content\": message.text}  # use\n",
      "r's queryOpenai Pr oject s:\n",
      "8        ]\n",
      "    )\n",
      "    reference.response = response['choices'][0]['message']['c\n",
      "ontent']\n",
      "    print(f\">>> chatGPT: \\n\\t{reference.response}\")\n",
      "    await bot.send_message(chat_id=message.chat.id, text=refe\n",
      "rence.response)\n",
      "hgh\n",
      "Def ines a gener al message handler  that t ak es an y message fr om the user ,  \n",
      "sends it t o the OpenAI API, and r etur ns a r esponse.\n",
      "print(f\">>> USER: \\n\\t{message.text}\")  Logs the user's message f or  \n",
      "debugging.\n",
      "response = openai.ChatCompletion.create(...)  Sends a r equest t o the OpenAI  \n",
      "API using the GPT model, p assing the con v ersation cont e x t (pr e vious  \n",
      "r esponse ) and the user's ne w message.\n",
      "reference.response = response['choices'][0]['message']['content']  St or es the  \n",
      "lat est r esponse fr om the OpenAI API in reference.response .\n",
      "await bot.send_message(...)  Sends the generat ed r esponse b ack t o the user .\n",
      "R e ason:  This function po w ers the main int eraction with the bot, using GPT  \n",
      "t o generat e r esponses b ased on the user ʼ s quer y and the st or ed  \n",
      "con v ersation cont e x t.\n",
      "python\n",
      "Copy code\n",
      "if __name__ == \"__main__\":\n",
      "    executor.start_polling(dispatcher, skip_updates=False)\n",
      "St ar t s t he bot  using polling t o continuousl y check f or ne w messages fr om  \n",
      "users.Openai Pr oject s:\n",
      "9R e ason:  P olling is a common method t o k eep the bot running and list ening  \n",
      "f or ne w messages. The skip_updates=False  ensur es that the bot pr ocesses  \n",
      "all messages, including ones that w er e sent while the bot was of fline.\n",
      "A u d i o  T r a n s l a t i o n :\n",
      "I m p o r t i n g  L i b r a r i e s :\n",
      "python\n",
      "Copy code\n",
      "import openai\n",
      "import os\n",
      "from dotenv import load_dotenv\n",
      "from flask import Flask, request, jsonify, render_template\n",
      "import openai  Impor t s the OpenAI librar y t o int eract with OpenAI's APIs, such  \n",
      "as GPT 4 and Whisper .\n",
      "import os  Impor t s the os  librar y t o int eract with the operating syst em, which is  \n",
      "needed f or file handling (lik e r etr ie ving en vir onment v ar iables and file p aths).\n",
      "from dotenv import load_dotenv  Impor t s the load_dotenv  function t o lo ad  \n",
      "en vir onment v ar iables fr om a .env  file, ensur ing sensitiv e inf or mation (lik e API  \n",
      "k e ys) r emains secur e.\n",
      "from flask import Flask, request, jsonify, render_template  Impor t s necessar y  \n",
      "functions fr om Flask t o cr e at e a w eb ser v er , handle HTTP r equest s, r etur n  \n",
      "JSON r esponses, and r ender HTML t emplat es.\n",
      "L o a d i n g  E n v i r o n m e n t  V a r i a b l e s :Openai Pr oject s:\n",
      "10python\n",
      "Copy code\n",
      "load_dotenv()\n",
      "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
      "openai.api_key = OPENAI_API_KEY\n",
      "load_dotenv()  Lo ads the en vir onment v ar iables fr om the .env  file int o the  \n",
      "syst em.\n",
      "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  R etr ie v es the OpenAI API k e y fr om  \n",
      "the en vir onment v ar iables (st or ed secur el y in the .env  file ).\n",
      "openai.api_key = OPENAI_API_KEY  Set s the OpenAI API k e y t o authentic at e r equest s  \n",
      "made t o the OpenAI API.\n",
      "S e t t i n g  u p  t h e  F l a s k  A p p l i c a t i o n :\n",
      "python\n",
      "Copy code\n",
      "app = Flask(__name__)\n",
      "app.config[\"UPLOAD_FOLDER\"] = \"static\"\n",
      "app = Flask(__name__)  Initializ es the Flask applic ation. The __name__  v ar iable is  \n",
      "p assed t o t ell Flask wher e t o look f or r esour ces (t emplat es, st atic files, et c.).\n",
      "app.config[\"UPLOAD_FOLDER\"] = \"static\"  Configur es the loc ation f or sa ving  \n",
      "uplo aded files (in this c ase, the static  dir ect or y).\n",
      "D e f i n i n g  t h e  M a i n  R o u t e :\n",
      "python\n",
      "Copy code\n",
      "@app.route('/', methods=['GET', 'POST'])\n",
      "def main():\n",
      "    if request.method == \"POST\":Openai Pr oject s:\n",
      "11        language = request.form[\"language\"]\n",
      "        file = request.files[\"file\"]\n",
      "        if file:\n",
      "            filename = file.filename\n",
      "            file.save(os.path.join(app.config['UPLOAD_FOLDE\n",
      "R'], filename))\n",
      "            audio_file = open(\"static/Recording.mp3\", \"rb\")\n",
      "            transcript = openai.Audio.translate(\"whisper-1\",  \n",
      "audio_file)\n",
      "            response = openai.ChatCompletion.create(\n",
      "                    model=\"gpt-4\",\n",
      "                    messages = [{ \"role\": \"system\", \"conten\n",
      "t\": f\"You will be provided with a sentence in English, and yo\n",
      "ur task is to translate it into {language}\" },\n",
      "                                { \"role\": \"user\", \"content\":  \n",
      "transcript.text }],\n",
      "                    temperature=0,\n",
      "                    max_tokens=256\n",
      "                  )\n",
      "            return jsonify(response)\n",
      "    return render_template(\"index.html\")\n",
      "@app.route('/', methods=['GET', 'POST'])\n",
      "Defines a r out e f or the r oot URL  / ).\n",
      "Allo ws t w o t ypes of HTTP r equest s: GET  and POST .\n",
      "GET  Used t o lo ad the w eb p age.\n",
      "POST  Used when submit ting f or m dat a (language choice and file uplo ad).\n",
      "F o r m  H a n d l i n g :Openai Pr oject s:\n",
      "12python\n",
      "Copy code\n",
      "if request.method == \"POST\":\n",
      "    language = request.form[\"language\"]\n",
      "    file = request.files[\"file\"]\n",
      "If the r equest is a POST , it me ans the user has submit t ed the f or m (with a  \n",
      "language selection and an audio file ).\n",
      "language = request.form[\"language\"]  R etr ie v es the language select ed b y the user  \n",
      "fr om the f or m.\n",
      "file = request.files[\"file\"]  R etr ie v es the uplo aded audio file fr om the f or m.\n",
      "F i l e  H a n d l i n g :\n",
      "python\n",
      "Copy code\n",
      "if file:\n",
      "    filename = file.filename\n",
      "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filen\n",
      "ame))\n",
      "Checks if a file was uplo aded.\n",
      "filename = file.filename  Get s the file name of the uplo aded audio file.\n",
      "file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))  Sa v es the file in the  \n",
      "specified uplo ad f older ( static  dir ect or y) using the or iginal file name.\n",
      "U s i n g  O p e n A I  W h i s p e r  f o r  T r a n s c r i p t i o n :\n",
      "python\n",
      "Copy code\n",
      "audio_file = open(\"static/Recording.mp3\", \"rb\")Openai Pr oject s:\n",
      "13transcript = openai.Audio.translate(\"whisper-1\", audio_file)\n",
      "Opens the uplo aded audio file ( Recording.mp3 ) in binar y r e ad mode ( \"rb\" ).\n",
      "openai.Audio.translate(\"whisper-1\", audio_file)  Sends the audio file t o the Whisper  \n",
      "model (via OpenAI API f or transcr iption ( con v er t s speech in the audio file t o  \n",
      "t e x t).\n",
      "U s i n g  G P T - 4  f o r  T r a n s l a t i o n :\n",
      "python\n",
      "Copy code\n",
      "response = openai.ChatCompletion.create(\n",
      "        model=\"gpt-4\",\n",
      "        messages = [{ \"role\": \"system\", \"content\": f\"You will  \n",
      "be provided with a sentence in English, and your task is to t\n",
      "ranslate it into {language}\" },\n",
      "                    { \"role\": \"user\", \"content\": transcript.t\n",
      "ext }],\n",
      "        temperature=0,\n",
      "        max_tokens=256\n",
      "      )\n",
      "openai.ChatCompletion.create  Uses the GPT 4 model t o cr e at e a chat completion  \n",
      "( con v ersation).\n",
      "model=\"gpt-4\"  Specifies that GPT 4 is being used.\n",
      "messages  A list of messages is p assed t o GPT 4 , wher e the first message act s  \n",
      "as the syst em instruction (t elling GPT 4 it s r ole, t o translat e a sent ence t o a  \n",
      "specific language ) and the second message cont ains the transcr ipt (the  \n",
      "sent ence t o be translat ed).\n",
      "temperature=0  Set s the \" cr e ativit y\" of GPT 4's r esponse t o 0 (this mak es GPT \n",
      "4's output mor e det er ministic and less random).Openai Pr oject s:\n",
      "14max_tokens=256  Limit s the number of t ok ens (w or ds/charact ers) in GPT 4's  \n",
      "r esponse.\n",
      "R e t u r n i n g  t h e  R e s p o n s e :\n",
      "python\n",
      "Copy code\n",
      "return jsonify(response)\n",
      "Con v er t s the r esponse fr om GPT 4 int o a JSON f or mat and r etur ns it t o the  \n",
      "user .\n",
      "R e n d e r i n g  t h e  H T M L  F o r m :\n",
      "python\n",
      "Copy code\n",
      "return render_template(\"index.html\")\n",
      "If the r equest is a GET , the index.html  t emplat e is r ender ed, allo wing the user t o  \n",
      "submit the f or m.\n",
      "R u n n i n g  t h e  F l a s k  A p p l i c a t i o n :\n",
      "python\n",
      "Copy code\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(host=\"0.0.0.0\", debug=True, port=8080)\n",
      "if __name__ == \"__main__\"  Ensur es that the app runs onl y if the scr ipt is e x ecut ed  \n",
      "dir ectl y (and not impor t ed as a module ).\n",
      "app.run(host=\"0.0.0.0\", debug=True, port=8080)  Runs the Flask applic ation on all  \n",
      "net w or k int er f aces ( 0.0.0.0 ), with debugging enabled ( debug=True ), and on por t  Openai Pr oject s:\n",
      "158080 .\n",
      "Untit led\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Open the PDF and read its content\n",
    "with open(\"my.pdf\", \"rb\") as file:  # Use \"rb\" mode for binary files\n",
    "    reader = PdfReader(file)\n",
    "    \n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 4492\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize and split text into chunks\n",
    "num_token = model.get_num_tokens(text)\n",
    "print(\"Number of tokens:\", num_token)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=500, chunk_overlap=35)\n",
    "docs = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Summarize using the map_reduce chain\n",
    "chain = load_summarize_chain(llm=model, chain_type=\"map_reduce\")\n",
    "output = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Openai Projects is a collection of 10 projects that use Python and Flask to create bots that interact with users through Telegram and OpenAI. It uses modules to handle messages, store conversation history, and manage updates. The program uses the GPT-4 model to generate responses based on user input and previous context. It also includes features such as translating audio, handling file uploads, and limiting GPT-4's response. The code runs a Flask application on port 8080 with debugging enabled.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
